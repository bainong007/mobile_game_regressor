{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Validation/Cross-Validation For Model Selection\n",
    "\n",
    "This notebook demonstrates two typical workflows for using validation data to select models. It also demonstrates the use of some utility methods like generating **polynomial features**, converting **categorical features to \"dummy variable\"** binary columns, and **scaling features** when applying regularization.\n",
    "\n",
    "**Notebook Contents**\n",
    "\n",
    "> 1. Simple preprocessing and dummy variables\n",
    "> 2. Basic validation method: Train/validation/test\n",
    "> 3. Rigorous validation method: Cross-validation/test\n",
    "> 4. Making CV less manual via scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T18:06:29.609612Z",
     "start_time": "2019-07-22T18:06:28.956565Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Data loading: cars data set (using car characteristics to predict the price)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Load in the Game Data\n",
    "datafile = \"game_data_final_features.csv\"\n",
    "df=pd.read_csv(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>categories</th>\n",
       "      <th>contains_ads</th>\n",
       "      <th>downloads_and_revenue</th>\n",
       "      <th>has_iap</th>\n",
       "      <th>installs</th>\n",
       "      <th>most_popular_country</th>\n",
       "      <th>name</th>\n",
       "      <th>android</th>\n",
       "      <th>price</th>\n",
       "      <th>...</th>\n",
       "      <th>categories_Other</th>\n",
       "      <th>categories_Puzzle</th>\n",
       "      <th>categories_Role Playing</th>\n",
       "      <th>categories_Simulation</th>\n",
       "      <th>categories_Sports</th>\n",
       "      <th>categories_Strategy</th>\n",
       "      <th>revenue_club</th>\n",
       "      <th>revenue_clubx10</th>\n",
       "      <th>log_revenue</th>\n",
       "      <th>Free_Pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'downloads': '&lt; 5k', 'revenue': '$9k', 'reven...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>KIDS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.104980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Casual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'downloads': '5m', 'revenue': '&lt; $5k', 'reven...</td>\n",
       "      <td>0</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>Mini Block Craft</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.517193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'downloads': '&lt; 5k', 'revenue': '$10k', 'reve...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Wonder Boy: The Dragon's Trap</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 categories  contains_ads  \\\n",
       "0           0  Adventure           0.0   \n",
       "1           1     Casual           1.0   \n",
       "2           2  Adventure           0.0   \n",
       "\n",
       "                               downloads_and_revenue  has_iap    installs  \\\n",
       "0  {'downloads': '< 5k', 'revenue': '$9k', 'reven...        0      1000.0   \n",
       "1  {'downloads': '5m', 'revenue': '< $5k', 'reven...        0  10000000.0   \n",
       "2  {'downloads': '< 5k', 'revenue': '$10k', 'reve...        0      1000.0   \n",
       "\n",
       "  most_popular_country                           name  android  price  ...  \\\n",
       "0                   US                           KIDS      1.0   2.99  ...   \n",
       "1                   BR               Mini Block Craft      1.0   0.00  ...   \n",
       "2                   US  Wonder Boy: The Dragon's Trap      1.0   9.99  ...   \n",
       "\n",
       "  categories_Other categories_Puzzle  categories_Role Playing  \\\n",
       "0                0                 0                        0   \n",
       "1                0                 0                        0   \n",
       "2                0                 0                        0   \n",
       "\n",
       "  categories_Simulation  categories_Sports  categories_Strategy  revenue_club  \\\n",
       "0                     0                  0                    0             1   \n",
       "1                     0                  0                    0             1   \n",
       "2                     0                  0                    0             2   \n",
       "\n",
       "   revenue_clubx10  log_revenue  Free_Pay  \n",
       "0                1     9.104980         1  \n",
       "1                1     8.517193         0  \n",
       "2              100     9.210340         1  \n",
       "\n",
       "[3 rows x 46 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going to simplify things a bit by focusing on the numeric columns and a single categorical column, make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'categories', 'contains_ads', 'downloads_and_revenue',\n",
       "       'has_iap', 'installs', 'most_popular_country', 'name', 'android',\n",
       "       'price', 'publisher_country', 'publisher_name', 'rating',\n",
       "       'rating_breakdown', 'rating_count', 'revenue', 'downloads', 'one_star',\n",
       "       'two_star', 'three_star', 'four_star', 'five_star', 'ios', 'one_star_1',\n",
       "       'three_star_3', 'four_star_4', 'five_star_5', 'two_star_2',\n",
       "       'overall_rating', 'categories_Action', 'categories_Adventure',\n",
       "       'categories_Arcade', 'categories_Board', 'categories_Card',\n",
       "       'categories_Casino', 'categories_Casual', 'categories_Other',\n",
       "       'categories_Puzzle', 'categories_Role Playing', 'categories_Simulation',\n",
       "       'categories_Sports', 'categories_Strategy', 'revenue_club',\n",
       "       'revenue_clubx10', 'log_revenue', 'Free_Pay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Already have the categories set up.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "game = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we're ready to start modeling! We're going to try out the validation process to choose between 3 models: simple linear regression, linear regression with ridge regularization, and linear regression with 2nd degree polynomial features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2. Simple Validation Method: Train / Validation / Test\n",
    "\n",
    "Here we will break the data into 3 portions: 60% for training, 20% for validation (used to select the model), 20% for final testing evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge #ordinary linear regression + w/ ridge regularization\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "X = game.loc[:,['contains_ads', 'has_iap',\n",
    "       'android', 'ios', 'Free_Pay','rating_count', 'downloads',\n",
    "       'categories_Action','categories_Adventure', 'categories_Arcade', 'categories_Board',\n",
    "       'categories_Card', 'categories_Casino', 'categories_Casual',\n",
    "       'categories_Other', 'categories_Puzzle', 'categories_Role Playing',\n",
    "       'categories_Simulation', 'categories_Sports', 'categories_Strategy', \n",
    "       'overall_rating', 'one_star','two_star','three_star', 'four_star', 'five_star']]\n",
    "y = game.loc[:,['revenue']]\n",
    "# hold out 20% of the data for final testing\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hold out 20% of the data for validation testing\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we need some model setup: **when using regularization, we must standardize** the data so that all features are on the same scale (we subtract the mean of each column and divide by the standard deviation, giving us features with mean 0 and std 1). Since this scaling is part of our model, we need to scale using the training set feature distributions and apply the same scaling to validation and test without refitting the scaler. \n",
    "\n",
    "Also, we need to get **polynomial features** for the poly model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#set up the 3 models we're choosing from:\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.transform(X_val.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_val_poly = poly.transform(X_val.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can train, validate, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression val R^2: 0.268\n",
      "Ridge Regression val R^2: 0.297\n",
      "Degree 2 polynomial regression val R^2: -2.261\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear Regression val R^2: {lm.score(X_val, y_val):.3f}')\n",
    "\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge Regression val R^2: {lm_reg.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(f'Degree 2 polynomial regression val R^2: {lm_poly.score(X_val_poly, y_val):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check out that negative R^2, some severe overfitting! \n",
    "\n",
    "So having run this validation step, we see that the evidence points to simple linear regression being the best model. So our validation process lets us **select** that choice of model, and as our final step we retrain it on the entire chunk of train/val data and see how it does on test data:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression test R^2: 0.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=3.84167e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "lm_reg.fit(X,y)\n",
    "print(f'Linear Regression test R^2: {lm_reg.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Rigorous Validation Method: Cross-Validation / Test\n",
    "\n",
    "Here we will break the data into 2 portions: 80% for a cross-validated training process, and 20% for final testing evaluation. \n",
    "\n",
    "Remember that the idea of CV is to make efficient use of the data available to us (using 80% instead of 60% above), while also performing multiple validation checks. For k-fold CV, we come up with k train/validation splits of the whole chunk of data, in such a way that **each observation is in the validation set exactly 1 time**. Here's a helpful diagram:\n",
    "\n",
    "![](images/cross_validation_diagram.png)\n",
    "\n",
    "For simplicity we'll focus on linear regression and ridge regression (we also can feel pretty comfortable throwing out the full degree 2 polynomial regression based on the poor results above!) As we loop through our CV folds, we will train and validate both models and collect the results to compare at the end. Note that we scale the training features within the CV loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = game.loc[:,['contains_ads', 'has_iap',\n",
    "       'android', 'ios', 'Free_Pay','rating_count', 'downloads',\n",
    "       'categories_Action','categories_Adventure', 'categories_Arcade', 'categories_Board',\n",
    "       'categories_Card', 'categories_Casino', 'categories_Casual',\n",
    "       'categories_Other', 'categories_Puzzle', 'categories_Role Playing',\n",
    "       'categories_Simulation', 'categories_Sports', 'categories_Strategy', \n",
    "       'overall_rating', 'one_star','two_star','three_star', 'four_star', 'five_star']]\n",
    "y = game.loc[:,['revenue']]\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=28) #hold out 20% of the data for final testing\n",
    "\n",
    "#this helps with the way kf will generate indices below\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple regression scores:  [0.37389313504560184, 0.14269151038883976, 0.3908220128228935, 0.30201471730937146, 0.4973273390460588]\n",
      "Ridge scores:  [0.36921619058932, 0.1457945335894546, 0.396240500755199, 0.3033333311672918, 0.5209416871570955] \n",
      "\n",
      "Simple mean cv r^2: 0.341 +- 0.117\n",
      "Ridge mean cv r^2: 0.347 +- 0.123\n"
     ]
    }
   ],
   "source": [
    "#run the CV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 10)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The plot thickens! Our simple validation method above pointed to simple linear regression being better than ridge, but k-fold shows the opposite. The ridge model appears to be both better on average and has less varying results.\n",
    "\n",
    "**Since k-fold is more reliable than a single validation set, we select the ridge regression model**. This shows the dangers of relying on simple validation methods, especially when our sample sizes are small.\n",
    "\n",
    "Finally, see that we do better on the same test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression test R^2: 0.384\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_scaled,y)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seems like R^2 cannot get over 0.4 on all the training data and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Log for better or worst\n",
    "### Here is some Info for log\n",
    "numpy.log(x[, out]) = <ufunc 'log'>\n",
    "Natural logarithm, element-wise.\n",
    "\n",
    "The natural logarithm log is the inverse of the exponential function, so that log(exp(x)) = x. The natural logarithm is logarithm in base e.\n",
    "\n",
    "By taking logarithms of variables which are multiplicatively related and/or growing exponentially over time, we can often explain their behavior with linear models.\n",
    "\n",
    "It straightens out exponential growth patterns and reduces **heteroscedasticity** (i.e., stabilizes variance\n",
    "The marginal effect of one variable on the expected value of another is linear in terms of percentage changes rather than absolute changes.  In such cases, applying a natural log or diff-log transformation to both dependent and independent variables may be appropriate. \n",
    "\n",
    "Small changes in the natural log of a variable are directly interpretable as percentage changes\n",
    "\n",
    "\n",
    "\n",
    "1)Your variable has a right skew (mean > median). Taking the log would make the distribution of your transformed variable appear more symmetric (more normal). However, this is not a very good reason to log your variable. There are no regression assumptions that require your independent or dependent variables to be normal. However, if you have outliers in your dependent or independent variables, a log transformation could reduce the influence of those observations.\n",
    "\n",
    "2)The variance of your regression residuals are increasing with your regression predictions. Taking the log of your dependent and/or independent variables may eliminate the heteroscedasticity.\n",
    "\n",
    "3)Your regression residuals are non-normal. This may or may not be a problem for you. Even if your residuals are non-normal, your estimates may still be BLUE (best linear unbiased estimates). However in order for you to trust your inferences, you could log the dependent and/or independent variables and then check if the residuals are normal after the log transformation.\n",
    "\n",
    "4)Transforms a non-linear model into a linear model. In economics, the production function is a non-linear combination of labor (L) and capital (K) , ğ‘Œ=ğ¾ğ‘ğ¿ğ‘. Where ğ‘ and ğ‘ are parameters that you want to estimate. If you log both sides of the equation and add a constant ğ‘, ğ‘™ğ‘œğ‘”(ğ‘Œ)=ğ‘+ğ‘ğ‘™ğ‘œğ‘”(ğ¾)+ğ‘ğ‘™ğ‘œğ‘”(ğ¿). The latter equation can be estimated using linear regression.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In my case: why should I taking logarithms of my target \"Revenue\" or log transform.\n",
    "- 1) The revenue series has a minimal bound 0, in this case 5000. Use apply log to revenue makes it no longer bounded.\n",
    "\n",
    "- 2)It straightens out exponential growth patterns and reduces **heteroscedasticity** (i.e., stabilizes variance)\n",
    "\n",
    "- 3)We have heavy right tail or skew. Applying log make y looks more normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
